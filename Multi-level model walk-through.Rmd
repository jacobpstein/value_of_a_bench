---
title: "Multi-level model walk-through"
author: "Wizards Points"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
# Load packages
library(tidyverse) # the usual
library(readr) # fancy data load 
library(lme4) # multi-level models
library(performance) # model assessment
library(broom) # clean up
library(broom.mixed) # clean-up for mlms
library(sjPlot) # model plots
library(arm) # scaling the data
library(rstanarm) # bayesian model

# set seed
set.seed(5292023)

# load data---
df <- read_csv("03 Data/advanced player stats and team stats.csv", col_types = cols(...1 = col_skip(), X = col_skip())) %>% 
  mutate(bench = ifelse(starter == 0, 1, 0)) 

```

## Varying slopes? Varying intercepts?

Our dataset has bench and starter performance by team. Let's look at the relationship between net rating and win percentage by these groups

```{r, echo = FALSE, warning = FALSE, message= FALSE}
df %>% 
  filter(10>=gp) %>% # limit to players with 10 or more games
  ggplot(aes(x = (net_rating), y = (team_w_pct), col = starter_char)) +
  geom_point(shape = 21, stroke = 3, alpha = 0.3) +
  geom_smooth(mapping = aes(group = starter_char), method = "lm", se = FALSE, fullrange = TRUE) +
    scale_color_manual(values = c("#E41134", "#00265B")) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_classic() + 
  theme(legend.position = "top"
        , legend.title = element_blank()
        , text = element_text(size = 22)
        ) +
  labs(x = "Player Net Rating", y = "Team Win %"
       , title = "Starting and Bench Player Net Rating and\nOverall Team Win Percentage, 2011-23"
       , subtitle  = "Only players with 10 or more games included"
       , caption = "Data: nba.com/stats\nwizardspoints.substack.com"
  )


```

Ok, varying slopes...big time. What about bench performance only by team?

```{r, echo = FALSE, warning = FALSE}
df %>% 
  filter(10>=gp & starter == 0) %>% # limit to players with 10 or more games
  ggplot(aes(x = (net_rating), y = (team_w_pct), col = team_name)) +
  geom_point(shape = 21, stroke = 3, alpha = 0.3) +
  geom_smooth(mapping = aes(group = team_name), method = "lm", se = FALSE, fullrange = TRUE) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_classic() + 
  theme(legend.position = "NA"
        , legend.title = element_blank()
        ) +
  labs(x = "Player Net Rating", y = "Team Win %"
       , title = "Bench Player Net Rating and\nOverall Team Win Percentage by Team, 2011-23"
       , subtitle  = "Only players with 10 or more games included"
       , caption = "Data: nba.com/stats\nwizardspoints.substack.com"
  ) +
  viridis::scale_color_viridis(discrete = T) +
  facet_wrap(~team_name)



```

The intercept and slope values are pretty different for benches across different teams. The Nets and Suns have strongly positively correlated bench performance and net ratings, while the Clippers and Warriors have the opposite.

If we simply include a "starter" predictor in our model, we're estimating different intercepts for starters and bench net ratings--and we know the starter intercept is higher. If we want to know how starter status affects the slope of win percentage, that's a different specification, one with interactions. The interaction model essentially asks whether or not there is there a difference in the effect of net rating on win percentage for starters and bench players? If we don't include the interaction we assume that the slope between net rating and win percentage is the same for both starters and bench players.

We could estimate a two-stage regression to estimate the variation by starter status and then by team, or combine these into a multi-level model.


| Level  | Equation |
|:-------|:---------|
|Level 1 | $winpercentage_{ij} = \beta_{0j} + \beta_{1j}netrating_{ij} + \beta_{2ij}minutes_{ij} + E_{ij}$|}
|Level 2 | $\beta_{0j} = \gamma_{00} + \gamma_{10}starter_j + U_{0j}$|
|        | $\beta_{1j} = \gamma_{10} + \gamma_{11}starter_j + U_{1j}$|
|Combined| $winpercentage_{ij} = \gamma_{00} + \gamma_{01}netrating_{j} + \gamma_{10}minutes_{ij} + \gamma_{20}starter_{ij} + \gamma_{11}minutes_{ij}*starter_j + U_{0j} + U_{1j}starter_{j} + R_{ij}$|

With this model, we will be estimating seven different model parameters --- 5 fixed effects, 2 random effects:

1. $\gamma_{00}$: the fixed effect for the intercept, controlling for `net rating` , `minutes` and `starter`;
2. $\gamma_{01}$: the fixed effect for the slope of `net rating`, controlling for `starter` and `minutes`;
3. $\gamma_{10}$: the fixed effect for the slope of `minutes`, controlling for `starter` and `minutes`;
4. $\gamma_{20}$: the fixed effect for the slope of `starter`, controlling for `net rating` and `minutes`;
5. $\gamma_{11}$: the fixed effect for the cross-level interaction of`minutes` with `starter`, controlling for `net rating`;
6. $\tau_{01}$: a random effect capturing how a teamâ€™s mean win percentage varies around the overall mean win percentage, controlling for `net rating`, `minutes` and `starter`;
7. $\sigma^2$: a  random effect capturing the variance of players around their covariance with team win percentage, controlling for `net rating`, `minutes` and `starter`.

A cross-level interaction is interpreted like an interaction in OLS: the effect of starting status on the effect of net rating on win percentage.

```{r, warnings = F, message = F}

# let's create a new data frame just for our variables of interest and rescale them

df_mod <- df %>% 
  dplyr::select(team_w_pct, min, net_rating, starter_char, season, team_name, player_name, bench) %>% 
  # rescale
  mutate_at(.vars = c(1:3), .funs = arm::rescale) %>% 
  arrange(season, player_name)

mlm_1 <- lmer(team_w_pct ~  net_rating + min + bench + min:starter_char + (1|team_name), data = df_mod)

broom.mixed::tidy(mlm_1, conf.int = TRUE)
```
We can see from the output above and the plot below that there is a decent amount of uncertainty around our interaction term of interest. 

```{r}

plot_model(mlm_1)

```
```{r}
plot_model(mlm_1, type = "int") + theme_classic() +
  labs(x = "minutes Played"
       , y = "Team Win %"
       , title = "Predicted Team Win Percentage by Player Status"
       , caption = "data: nba.com/stats\nwizardspoints.substack.com"
  ) +
  scale_x_continuous(labels = scales::comma_format()) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme(legend.position = "top"
        , legend.title = element_blank()
        , text = element_text(size = 22))
```
Let's look at the specific team intercepts just for the bench. This will essentially give us a ranking of the interaction. 

We can see that for roughly half the league, their benches aren't doing much for them after we account for variation in net rating by team. 

```{r, warning = FALSE, message = F}

ranef_results <- broom.mixed::tidy(mlm_1, effects = "ran_vals", conf.int = TRUE)

ranef_results %>% 
  arrange(desc(estimate)) %>% 
  ggplot(aes(x = estimate, y = reorder(level, estimate), xmin = conf.low, xmax = conf.high)) + 
  geom_vline(xintercept = 0, linetype = 6) +
  geom_pointrange(aes(col = estimate)) +
  viridis::scale_color_viridis(option = "E") +
  theme_classic() +
  theme(legend.position = "NA") +
  labs(x = "Mean effect of bench minutes", y = "", title = "What is the average effect of bench minutes\nby team on win percentage?", caption = "Data: NBA.com/stats\nwizardspoints.substack.com")
```

# Bring in the original DAG

In our original design, the data are collapsed by starter-bench levels across teams. This still works within a multi-level framework, but likely increases some of the variance of our measures. We should get roughly the same results, but maybe with a little more noise since we are not working at a player-unit level but at a player-status unit level. 

```{r, message = F, warning=FALSE}


df_collapsed <- df %>% 
  # drop our character variables
  dplyr::select(team_name, season, starter_char, net_rating, team_w_pct, min) %>%
  # collapse by team, season, and starter
  group_by(team_name, season, starter_char) %>% 
  summarize(net_rating = mean(net_rating, na.rm=T)
            , team_w_pct = mean(team_w_pct, na.rm=T)
            , min = sum(min, na.rm=T)
            ) %>% 
  ungroup() %>% 
  mutate_at(.vars = c("net_rating", "min", "team_w_pct"), .funs = arm::rescale) 


mlm_2 <- lmer(team_w_pct~ net_rating + min + starter_char*min + (1|team_name), data = df_collapsed)



```
Our model specification is the same for this model, the data are what have changed.

```{r, warning = FALSE}
broom.mixed::tidy(mlm_2, conf.int = TRUE)

```

```{r, warning = FALSE, message = FALSE, echo = FALSE}
ranef_results2 <- broom.mixed::tidy(mlm_2, effects = "ran_vals", conf.int = TRUE)

ranef_results2 %>% 
  arrange(desc(estimate)) %>% 
  ggplot(aes(x = estimate, y = reorder(level, estimate), xmin = conf.low, xmax = conf.high)) + 
  geom_vline(xintercept = 0, linetype = 6) +
  geom_pointrange(aes(col = estimate)) +
  viridis::scale_color_viridis(option = "E") +
  theme_classic() +
  theme(legend.position = "NA") +
  labs(x = "Mean effect of bench minutes relative to starter minutes", y = "", title = "How do bench minutes compare to starter minutes by team?", caption = "Data: NBA.com/stats\nwizardspoints.substack.com")

```

Let's look at the interaction effect. 

```{r}
plot_model(mlm_2, type = "int") + theme_classic() +
  labs(x = "minutes Played"
       , y = "Team Win %"
       , title = "Predicted Team Win Percentage by Unit Status"
       , caption = "data: nba.com/stats\nwizardspoints.substack.com"
  ) +
  scale_x_continuous(labels = scales::comma_format()) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme(legend.position = "top"
        , legend.title = element_blank()
        , text = element_text(size = 22))
```
## Getting back to our initial DAG model

We want to run a slightly different model on wider data where instead of an interaction term, we use the actual value for bench minutes, controlling for starter and bench net ratings, with random effects by team. 

For context, let's just look at the relationship between bench minutes and win percentage.
```{r}

df_wide <- df %>% 
  # drop our character variables
  dplyr::select(team_name, season, starter_char, net_rating, team_w_pct) %>% 
  # collapse by team, season, and starter
  group_by(team_name, season, starter_char) %>% 
  summarize(net_rating = mean(net_rating, na.rm=T)
            , team_w_pct = mean(team_w_pct, na.rm=T)
            ) %>%
  ungroup() %>% 
  mutate_at(.vars = c("net_rating",  "team_w_pct"), .funs = arm::rescale) %>% 
  pivot_wider(names_from = starter_char, values_from = net_rating) %>% 
  left_join(
    df %>% 
      # drop our character variables
      dplyr::select(team_name, season, starter, net_rating, min, team_w_pct) %>% 
      group_by(team_name, season, starter) %>% 
      summarize(total_bench_minutes = sum(min, na.rm=T)
                ) %>% 
      filter(starter == 0) %>% 
      dplyr::select(-starter) %>% 
      ungroup() %>% 
      mutate(total_bench_minutes = arm::rescale(total_bench_minutes))
  )

df %>% 
  # drop our character variables
  dplyr::select(team_name, season, starter_char, net_rating, team_w_pct) %>% 
  # collapse by team, season, and starter
  group_by(team_name, season, starter_char) %>% 
  summarize(net_rating = mean(net_rating, na.rm=T)
            , team_w_pct = mean(team_w_pct, na.rm=T)
            ) %>%
  ungroup() %>% 
  pivot_wider(names_from = starter_char, values_from = net_rating) %>% 
  left_join(
    df %>% 
      # drop our character variables
      dplyr::select(team_name, season, starter, net_rating, min, team_w_pct) %>% 
      group_by(team_name, season, starter) %>% 
      summarize(total_bench_minutes = sum(min, na.rm=T)
                ) %>% 
      filter(starter == 0) %>% 
      dplyr::select(-starter) ) %>% 
      ungroup() %>% 
ggplot(aes(x = total_bench_minutes, y = team_w_pct, col = team_name)) +
  geom_point(shape = 21, stroke = 3, alpha = 0.3) +
  geom_smooth(mapping = aes(group = team_name), method = "lm", se = FALSE, fullrange = TRUE) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_classic() + 
  theme(legend.position = "NA"
        , legend.title = element_blank()
        ) +
  labs(x = "Total Bench Minutes", y = "Team Win %"
       , title = "Total Bench Minutes and\nOverall Team Win Percentage by Team, 2011-23"
       , caption = "Data: nba.com/stats\nwizardspoints.substack.com"
  ) +
  viridis::scale_color_viridis(discrete = T) +
  facet_wrap(~team_name)
```

In a model context, this takes the following form: 
$$
\begin{aligned}
  \operatorname{team\_w\_pct}_{i}  &\sim N \left(\mu, \sigma^2 \right) \\
    \mu &=\alpha_{j[i]} + \beta_{1}(\operatorname{Bench}) + \beta_{2}(\operatorname{Starter}) + \beta_{3}(\operatorname{total\_bench\_minutes}) \\
    \alpha_{j}  &\sim N \left(\mu_{\alpha_{j}}, \sigma^2_{\alpha_{j}} \right)
    \text{, for team_name j = 1,} \dots \text{,J}
\end{aligned}
$$

```{r, warning = F}


mlm_3 <- lmer(team_w_pct~ Bench + Starter + total_bench_minutes + (1|team_name), data = df_wide)


broom.mixed::tidy(mlm_3, conf.int = TRUE)

```

Ok, it looks like our overall mean effect, not split out by team is lower. Let's look at the intercepts, i.e., the overall team level effects. It's important to note that we have left the realm of separability; we're not comparing bench minutes to starter minutes, but estimating the effect of bench minutes after accounting for bench and starter performance, as well as team-level variation. 

```{r}
ranef_results3 <- broom.mixed::tidy(mlm_3, effects = "ran_vals", conf.int = TRUE)

ranef_results3 %>% 
  arrange(desc(estimate)) %>% 
  ggplot(aes(x = estimate, y = reorder(level, estimate), xmin = conf.low, xmax = conf.high)) + 
  geom_vline(xintercept = 0, linetype = 6) +
  geom_pointrange(aes(col = estimate)) +
  viridis::scale_color_viridis(option = "E") +
  theme_classic() +
  theme(legend.position = "NA") +
  labs(x = "Mean effect of bench minutes", y = "", title = "What is the effect of bench minutes by team?", caption = "Data: NBA.com/stats\nwizardspoints.substack.com")

```

So, we see that for most teams, there is a lot of uncertainty around the mean values (could be positive, could be negative), but with generally the same ranking as the other models, which is kind of reassuring. Notably, there are a couple of teams for whom bench minutes are actively hurting them, on average, but the Wizards aren't in this group. 

### Let's bring in some priors

We know a thing or two about our parameters from watching basketball. Specifically, that starters are good and bench players are typically not as good and bench minutes are not the minutes fans generally go to see (present company excluded).

While Stan defaults to useful, but weakly informative priors, to constrain the uncertainty around the estimates, we can use informative priors based on these assumptions to better estimate the distribution for each parameter. For example, we might think that the bench performance parameter generally has the characteristics $\beta_{1}(\operatorname{Bench}) \in (-5, 3)$, while starter performance is closer to something like $\beta_{2}(\operatorname{Starter}) \in (-1, 6)$, and $\beta_{3}(\operatorname{total bench minutes}) \in (-0.35, -0.01)$ The prior on bench minutes reflects the re-scaled values (i.e., centered and divided by 2 sd's), so we're just saying that we thinking bench minutes are mostly negatively correlated with win percentage here. 

We can also set a prior on our outcome of win percentage with the following characteristics:
                            $\sim N \left(0.5, 0.1 \right)$
                            
If we had thoughts on the distribution of the error of our model, we could also fit a prior to that, but I don't really have any thoughts on this, so we'll just keep the default.

```{r, warning = FALSE, message = FALSE, results="hide"}
prior_mlm <- normal(location = c(-1, 2.5, -0.18), scale = c(4, 3.5, .17), autoscale = FALSE)


prior_intercept_mlm <- normal(location = 0.5, scale = .1, autoscale = F)


mlm_4 <- stan_lmer(team_w_pct~ Bench + Starter + total_bench_minutes + (1|team_name)
                   , data = df_wide, prior = prior_mlm
                   , prior_intercept = prior_intercept_mlm # on second thought lets drop the intercept prior
                   )


broom.mixed::tidy(mlm_4, conf.int = TRUE)

```

We can see that the median estimate on bench minutes is a bit more constrained (or in normal language, "lower") than in our previous model. The figure below also uses 90% credible intervals per McElreath. 

```{r, warning = FALSE, message = FALSE}
ranef_results4 <- broom.mixed::tidyMCMC(mlm_4, effects = "ran_vals", conf.int = TRUE, conf.level=.9)

ranef_results4 %>% 
    filter(grepl("team_name:", term)==T & grepl("Sigma", term)!=T) %>% 
    mutate(term = gsub("[_]", " ", substr(term, 25, nchar(term)-1))) %>% 
  arrange(desc(estimate)) %>% 
  ggplot(aes(x = estimate, y = reorder(term, estimate), xmin = conf.low, xmax = conf.high)) + 
  geom_vline(xintercept = 0, linetype = 6) +
  geom_pointrange(aes(col = estimate)) +
  viridis::scale_color_viridis(option = "E") +
  theme_classic() +
  theme(legend.position = "NA") +
  labs(x = "Mean effect of bench minutes", y = "", title = "What is the effect of bench minutes by team?", subtitle = "Estimates using prior information", caption = "Data: NBA.com/stats\nwizardspoints.substack.com")

```

## A linear model

For comparison's sake, we can see how the multi-level structure compares to a linear model, with the following familiar specification:
$$
\operatorname{team\_w\_pct} = \alpha + \beta_{1}(\operatorname{Bench}) + \beta_{2}(\operatorname{Starter}) + \beta_{3}(\operatorname{total\_bench\_minutes}) + \epsilon
$$

```{r}

m1 <- lm(team_w_pct ~ 
           Bench 
         + Starter
         +  total_bench_minutes
         , data = df_wide)

broom::tidy(m1, conf.int = TRUE)

```

We can see the multi-level structure at work in the difference overall mean values for bench minutes: lower error, lower magnitude of effect. If we want to re-create the above plot, we can see this difference by team.

```{r, warning = FALSE}

df_wide2 <- df_wide %>% bind_cols(predict(m1, interval = "confidence"))

df_wide2 %>% 
  group_by(team_name) %>% 
  summarize(fit = mean(fit, na.rm=T)
            , lwr = mean(lwr, na.rm=T)
            , upr = mean(upr, na.rm=T)) %>% 
ggplot(aes(x = fit, y = reorder(team_name, fit), xmin = lwr, xmax = upr)) + 
  geom_vline(xintercept = 0, linetype = 6) +
  geom_pointrange(aes(col = fit)) +
  viridis::scale_color_viridis(option = "E") +
  theme_classic() +
  theme(legend.position = "NA") +
  labs(x = "Mean effect of bench minutes", y = "", title = "What is the effect of bench minutes by team?", subtitle = "Linear Regression Results", caption = "Data: NBA.com/stats\nwizardspoints.substack.com")

```

